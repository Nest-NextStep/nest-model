{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\nazni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\nazni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nazni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nazni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nazni\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazni\\AppData\\Local\\Temp\\ipykernel_36828\\2986868959.py:1: DtypeWarning: Columns (93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_set = pd.read_csv('data//data.csv', delimiter='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R1  R2  R3  R4  R5  R6  R7  R8  I1  I2  ...  orientation  race  voted  \\\n",
      "0   3   4   3   1   1   4   1   3   5   5  ...            1     1      2   \n",
      "1   1   1   2   4   1   2   2   1   5   5  ...            3     4      1   \n",
      "2   2   1   1   1   1   1   1   1   4   1  ...            1     4      2   \n",
      "3   3   1   1   2   2   2   2   2   4   1  ...            1     1      2   \n",
      "4   4   1   1   2   1   1   1   2   5   5  ...            3     1      2   \n",
      "\n",
      "   married  familysize  uniqueNetworkLocation  country  source      major  \\\n",
      "0        1           1                      1       US       2        NaN   \n",
      "1        2           3                      1       US       1    Nursing   \n",
      "2        1           1                      1       US       1        NaN   \n",
      "3        1           1                      1       CN       0        NaN   \n",
      "4        1           4                      1       PH       0  education   \n",
      "\n",
      "   Unnamed: 93  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('data//data.csv', delimiter='\\t')\n",
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Handle duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values:\n",
      "country\n",
      "major\n",
      "Unnamed: 93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Check for null values in each column\n",
    "null_columns = train_set.columns[train_set.isnull().any()]\n",
    "\n",
    "# Display columns with null values\n",
    "print(\"Columns with null values:\")\n",
    "for col in null_columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in respondent's answer. Country can be dropped (not relevant) and Major will be pre-processed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(columns=['country'])\n",
    "train_set = train_set.dropna(subset=['major'])\n",
    "train_set = train_set.drop(columns=['Unnamed: 93'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_set['major'] = label_encoder.fit_transform(train_set['major'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with major for all other attributes:\n",
      "major     1.000000\n",
      "S3        0.096814\n",
      "S5        0.085407\n",
      "gender    0.074262\n",
      "S8        0.062371\n",
      "            ...   \n",
      "VCL2     -0.070979\n",
      "VCL5     -0.074718\n",
      "E5       -0.075433\n",
      "C6       -0.076737\n",
      "VCL13    -0.097827\n",
      "Name: major, Length: 92, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_with_main = train_set.corr()['major']\n",
    "sorted_correlation = correlation_with_main.sort_values(ascending=False)\n",
    "\n",
    "# Display correlation with main attribute for all other attributes\n",
    "print(\"Correlation with\", 'major', \"for all other attributes:\")\n",
    "print(sorted_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter untuk masing masing pertanyaan RIASEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4   -0.063783\n",
      "R6   -0.044292\n",
      "R2   -0.030956\n",
      "R7   -0.030565\n",
      "R8   -0.028638\n",
      "R1   -0.026375\n",
      "R3   -0.024054\n",
      "R5   -0.016933\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "r_columns = [col for col in sorted_correlation.index if col.startswith('R')]\n",
    "r_correlations = sorted_correlation[r_columns]\n",
    "r_correlations_sorted = r_correlations.reindex(r_correlations.abs().sort_values(ascending=False).index)\n",
    "print(r_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I8   -0.046517\n",
      "I1    0.035950\n",
      "I4    0.033164\n",
      "I7    0.013177\n",
      "I2    0.012164\n",
      "I5    0.008699\n",
      "I6   -0.006355\n",
      "I3   -0.005188\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i_columns = [col for col in sorted_correlation.index if col.startswith('I')]\n",
    "i_correlations = sorted_correlation[i_columns]\n",
    "i_correlations_sorted = i_correlations.reindex(i_correlations.abs().sort_values(ascending=False).index)\n",
    "print(i_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A6   -0.039260\n",
      "A8   -0.033771\n",
      "A5   -0.032443\n",
      "A4   -0.029286\n",
      "A3   -0.028107\n",
      "A2   -0.022327\n",
      "A1   -0.020827\n",
      "A7   -0.016896\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "a_columns = [col for col in sorted_correlation.index if col.startswith('A')]\n",
    "a_correlations = sorted_correlation[a_columns]\n",
    "a_correlations_sorted = a_correlations.reindex(a_correlations.abs().sort_values(ascending=False).index)\n",
    "print(a_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3    0.096814\n",
      "S5    0.085407\n",
      "S8    0.062371\n",
      "S6    0.042938\n",
      "S7    0.014250\n",
      "S1    0.006551\n",
      "S4    0.001472\n",
      "S2   -0.001219\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s_columns = [col for col in sorted_correlation.index if col.startswith('S')]\n",
    "s_correlations = sorted_correlation[s_columns]\n",
    "s_correlations_sorted = s_correlations.reindex(s_correlations.abs().sort_values(ascending=False).index)\n",
    "print(s_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5   -0.075433\n",
      "E3   -0.050543\n",
      "E7   -0.034889\n",
      "E8   -0.033562\n",
      "E1   -0.031490\n",
      "E4    0.019264\n",
      "E6   -0.011198\n",
      "E2   -0.007715\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "e_columns = [col for col in sorted_correlation.index if col.startswith('E')]\n",
    "e_correlations = sorted_correlation[e_columns]\n",
    "e_correlations_sorted = e_correlations.reindex(e_correlations.abs().sort_values(ascending=False).index)\n",
    "print(e_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C6   -0.076737\n",
      "C7   -0.067660\n",
      "C5   -0.067407\n",
      "C3   -0.066505\n",
      "C8   -0.052127\n",
      "C2   -0.043965\n",
      "C1   -0.041057\n",
      "C4   -0.034972\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "c_columns = [col for col in sorted_correlation.index if col.startswith('C')]\n",
    "c_correlations = sorted_correlation[c_columns]\n",
    "c_correlations_sorted = c_correlations.reindex(c_correlations.abs().sort_values(ascending=False).index)\n",
    "print(c_correlations_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter VCL Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCL13   -0.097827\n",
      "VCL5    -0.074718\n",
      "VCL2    -0.070979\n",
      "VCL14   -0.061739\n",
      "VCL15   -0.058985\n",
      "VCL3    -0.046890\n",
      "VCL4    -0.045311\n",
      "VCL10   -0.042534\n",
      "VCL11   -0.037396\n",
      "VCL1    -0.035642\n",
      "VCL16   -0.023088\n",
      "VCL12   -0.021183\n",
      "VCL8     0.013887\n",
      "VCL7    -0.011596\n",
      "VCL6    -0.007161\n",
      "VCL9     0.006514\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "vcl_columns = [col for col in sorted_correlation.index if col.startswith('VCL')]\n",
    "vcl_correlations = sorted_correlation[vcl_columns]\n",
    "vcl_correlations_sorted = vcl_correlations.reindex(vcl_correlations.abs().sort_values(ascending=False).index)\n",
    "print(vcl_correlations_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter TIPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIPI7     0.029723\n",
      "TIPI5    -0.022685\n",
      "TIPI2    -0.014648\n",
      "TIPI10    0.012859\n",
      "TIPI4     0.009722\n",
      "TIPI3    -0.007150\n",
      "TIPI1     0.006641\n",
      "TIPI9    -0.003497\n",
      "TIPI8     0.003417\n",
      "TIPI6    -0.002580\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tipi_columns = [col for col in sorted_correlation.index if col.startswith('TIPI')]\n",
    "tipi_correlations = sorted_correlation[tipi_columns]\n",
    "tipi_correlations_sorted = tipi_correlations.reindex(tipi_correlations.abs().sort_values(ascending=False).index)\n",
    "print(tipi_correlations_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Pertanyaan diluar RIASEC, VCL, TIPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major                    1.000000\n",
      "gender                   0.074262\n",
      "education               -0.059594\n",
      "religion                 0.053448\n",
      "uniqueNetworkLocation    0.039981\n",
      "engnat                   0.031636\n",
      "voted                    0.031209\n",
      "orientation              0.023703\n",
      "married                 -0.012725\n",
      "race                     0.011715\n",
      "urban                   -0.006309\n",
      "introelapse             -0.005920\n",
      "familysize               0.005554\n",
      "surveyelapse            -0.004353\n",
      "age                      0.002779\n",
      "testelapse              -0.002557\n",
      "source                  -0.001790\n",
      "hand                     0.001122\n",
      "Name: major, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define the letters to exclude\n",
    "exclude_letters = ['R', 'I', 'A', 'S', 'E', 'C', 'TIPI', 'VCL']  \n",
    "\n",
    "#Filter columns that do not start with the specified letters\n",
    "filtered_columns = [col for col in sorted_correlation.index if not any(col.startswith(letter) for letter in exclude_letters)]\n",
    "\n",
    "# Create a DataFrame for filtered columns and their correlations\n",
    "filtered_correlations = sorted_correlation[filtered_columns]\n",
    "\n",
    "# Sort the filtered correlations\n",
    "filtered_correlations_sorted = filtered_correlations.reindex(filtered_correlations.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Display the sorted correlations\n",
    "print(filtered_correlations_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Question Based on Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(columns=['R3'])\n",
    "train_set = train_set.drop(columns=['R5'])\n",
    "train_set = train_set.drop(columns=['I3'])\n",
    "train_set = train_set.drop(columns=['I6'])\n",
    "train_set = train_set.drop(columns=['A7'])\n",
    "train_set = train_set.drop(columns=['A1'])\n",
    "train_set = train_set.drop(columns=['S2'])\n",
    "train_set = train_set.drop(columns=['S4'])\n",
    "train_set = train_set.drop(columns=['E2'])\n",
    "train_set = train_set.drop(columns=['E6'])\n",
    "train_set = train_set.drop(columns=['C4'])\n",
    "train_set = train_set.drop(columns=['C1'])\n",
    "train_set = train_set.drop(columns=['VCL9'])\n",
    "train_set = train_set.drop(columns=['VCL7'])\n",
    "train_set = train_set.drop(columns=['VCL8'])\n",
    "train_set = train_set.drop(columns=['VCL16'])\n",
    "train_set = train_set.drop(columns=['surveyelapse'])\n",
    "train_set = train_set.drop(columns=['testelapse'])\n",
    "train_set = train_set.drop(columns=['introelapse'])\n",
    "train_set = train_set.drop(columns=['source'])\n",
    "train_set = train_set.drop(columns=['uniqueNetworkLocation'])\n",
    "train_set = train_set.drop(columns=['hand'])\n",
    "train_set = train_set.drop(columns=['age'])\n",
    "train_set = train_set.drop(columns=['familysize'])\n",
    "train_set = train_set.drop(columns=['urban'])\n",
    "train_set = train_set.drop(columns=['race'])\n",
    "train_set = train_set.drop(columns=['married'])\n",
    "train_set = train_set.drop(columns=['orientation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazni\\AppData\\Local\\Temp\\ipykernel_36828\\2323174376.py:3: DtypeWarning: Columns (93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trainmajor_df = pd.read_csv('data//data.csv', delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "# DONT DO IT AGAIN AFTER RUN THE NEXT CODE\n",
    "\n",
    "trainmajor_df = pd.read_csv('data//data.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmajor_df = trainmajor_df.drop(columns=['country'])\n",
    "trainmajor_df = trainmajor_df.dropna(subset=['major'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['Unnamed: 93'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmajor_df = trainmajor_df.drop(columns=['R3'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['R5'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['I3'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['I6'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['A7'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['A1'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['S2'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['S4'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['E2'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['E6'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['C4'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['C1'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['VCL9'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['VCL7'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['VCL8'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['VCL16'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['surveyelapse'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['testelapse'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['introelapse'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['source'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['uniqueNetworkLocation'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['hand'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['age'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['familysize'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['urban'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['race'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['married'])\n",
    "trainmajor_df = trainmajor_df.drop(columns=['orientation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psychology: 6861\n",
      "Psychology: 5763\n",
      "English: 2342\n",
      "Business: 2290\n",
      "Biology: 1289\n",
      "Nursing: 1275\n",
      "business: 1166\n",
      "Education: 1162\n",
      "nursing: 839\n",
      "Psychology : 821\n",
      "engineering: 773\n",
      "Accounting: 730\n",
      "Economics: 730\n",
      "civil engineering: 675\n",
      "Law: 667\n",
      "biology: 655\n",
      "english: 649\n",
      "Computer Science: 643\n",
      "History: 631\n",
      "education: 607\n",
      "Marketing: 571\n",
      "Engineering: 555\n",
      "Finance: 532\n",
      "Sociology: 530\n",
      "Business Administration: 481\n",
      "Criminal Justice: 477\n",
      "Management: 443\n",
      "accounting: 437\n",
      "Medicine: 420\n",
      "law: 400\n",
      "Communications: 394\n",
      "computer science: 365\n",
      "Political Science: 351\n",
      "no: 350\n",
      "Business Management: 337\n",
      "Chemistry: 331\n",
      "Social Work: 319\n",
      "Music: 319\n",
      "Counseling: 317\n",
      "Science: 309\n",
      "Art: 304\n",
      "Mathematics: 304\n",
      "sociology: 301\n",
      "Communication: 293\n",
      "medicine: 292\n",
      "economics: 291\n",
      "management: 288\n",
      "Mechanical Engineering: 287\n",
      "Physics: 282\n",
      "criminal justice: 281\n",
      "Business : 276\n",
      "psychology : 274\n",
      "mechanical engineering: 273\n",
      "counseling: 266\n",
      "history: 266\n",
      "Architecture: 261\n",
      "marketing: 252\n",
      "Philosophy: 245\n",
      "Journalism: 242\n",
      "social work: 227\n",
      "none: 217\n",
      "science: 216\n",
      "IT: 206\n",
      "architecture: 202\n",
      "finance: 199\n",
      "chemistry: 198\n",
      "Design: 195\n",
      "art: 191\n",
      "Electrical Engineering: 191\n",
      "Nursing : 186\n",
      "undecided: 186\n",
      "political science: 185\n",
      "business management: 183\n",
      "Information Technology: 182\n",
      "English : 182\n",
      "Human Services: 179\n",
      "Anthropology: 178\n",
      "Civil engineering: 174\n",
      "chemical engineering: 174\n",
      "-: 174\n",
      "physics: 172\n",
      "electrical engineering: 171\n",
      "medical: 170\n",
      "communications: 168\n",
      "Biochemistry: 164\n",
      "business administration: 158\n",
      "Human Resources: 158\n",
      "Math: 157\n",
      "Civil Engineering: 154\n",
      "Commerce: 154\n",
      "Kinesiology: 153\n",
      "mathematics: 153\n",
      "Graphic Design: 150\n",
      "Undecided: 145\n",
      "philosophy: 144\n",
      "Liberal Arts: 141\n",
      "PSYCHOLOGY: 140\n",
      "Chemical Engineering: 139\n",
      "Education : 138\n",
      "communication: 138\n",
      "Computer science: 138\n",
      "music: 138\n",
      "Geography: 137\n",
      "Biology : 130\n",
      "General Studies: 130\n",
      "No: 129\n",
      "Linguistics: 127\n",
      "Computer Engineering: 126\n",
      "Medical: 124\n",
      "Arts: 123\n",
      "International Relations: 122\n",
      "Accountancy: 121\n",
      "Pharmacy: 117\n",
      "Engineering : 111\n",
      "French: 109\n",
      "commerce: 106\n",
      "Mechanical engineering: 105\n",
      "Film: 104\n",
      "pharmacy: 103\n",
      "Politics: 102\n",
      "Criminology: 102\n",
      "Neuroscience: 101\n",
      "journalism: 101\n",
      "math: 100\n",
      "design: 99\n",
      "Social work: 99\n",
      "Geology: 98\n",
      "computer engineering: 97\n",
      "anthropology: 97\n",
      "Teaching: 95\n",
      "liberal arts: 94\n",
      "Spanish: 92\n",
      "Elementary Education: 90\n",
      "Social Science: 89\n",
      "Health Science: 89\n",
      "Management : 89\n",
      "Accounting : 89\n",
      "Environmental Science: 87\n",
      "MBA: 87\n",
      "kinesiology: 86\n",
      "Early Childhood Education: 84\n",
      "Public Health: 84\n",
      "Literature: 83\n",
      "Electrical engineering: 82\n",
      "International Business: 82\n",
      "Exercise Science: 81\n",
      "Hospitality: 77\n",
      "Marketing : 76\n",
      "Human Resource Management: 75\n",
      "Fine Arts: 75\n",
      "human services: 74\n",
      "arts: 72\n",
      "Theology: 70\n",
      "Chemical engineering: 69\n",
      "Medicine : 68\n",
      "teaching: 68\n",
      "Tourism: 68\n",
      "Business management: 68\n",
      "HR: 67\n",
      "Nutrition: 67\n",
      "general studies: 66\n",
      "Business Administration : 65\n",
      "business : 65\n",
      "Humanities: 65\n",
      "social science: 65\n",
      "geography: 65\n",
      "graphic design: 64\n",
      "Theatre: 64\n",
      "nursing : 62\n",
      "biochemistry: 61\n",
      "History : 61\n",
      "accountancy: 61\n",
      "Art History: 60\n",
      "Architecture : 60\n",
      "Health Sciences: 60\n",
      "psycology: 59\n",
      "English Literature: 59\n",
      "Political science: 59\n",
      "Sociology : 58\n",
      "economy: 57\n",
      "Health: 57\n",
      "criminology: 56\n",
      "Physical Therapy: 55\n",
      "Criminal justice: 55\n",
      "Economics : 55\n",
      "Communication : 54\n",
      "na: 54\n",
      "Business administration: 54\n",
      "Microbiology: 53\n",
      "Advertising: 53\n",
      "information technology: 52\n",
      "Mechanical engineering : 51\n",
      "Languages: 51\n",
      "Civil engineering : 51\n",
      "Fine Art: 50\n",
      "ENGLISH: 50\n",
      "Rehabilitation Services: 50\n",
      "Media: 50\n",
      "Photography: 50\n",
      "Special Education: 49\n",
      "Biotechnology: 49\n",
      "Liberal Studies: 49\n",
      "Music Education: 48\n",
      "linguistics: 48\n",
      "Maths: 48\n",
      "Software Engineering: 48\n",
      "Biomedical Engineering: 48\n",
      "Dentistry: 47\n",
      "Political Science : 46\n",
      "international relations: 46\n",
      "Business Management : 46\n",
      "Statistics: 46\n",
      "idk: 46\n",
      "tourism: 45\n",
      "software engineering: 45\n",
      "geology: 44\n",
      "counselling: 44\n",
      "Human Development: 44\n",
      "Animal Science: 44\n",
      "Counselling: 44\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah kemunculan setiap major\n",
    "major_counts = trainmajor_df['major'].value_counts()\n",
    "\n",
    "# Mengurutkan major berdasarkan jumlah kemunculan\n",
    "sorted_major_counts = major_counts.sort_values(ascending=False)\n",
    "\n",
    "# Memilih 70 major teratas\n",
    "top_major_counts = sorted_major_counts.head(220)\n",
    "\n",
    "# Menampilkan 70 major dominan beserta jumlah kemunculannya\n",
    "for major, count in top_major_counts.items():\n",
    "    print(f\"{major}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
